{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibo870U8uYwn",
        "colab_type": "text"
      },
      "source": [
        "# Example 3 - Pre-trained models for image classification\n",
        "\n",
        "Available models are here:\n",
        "\n",
        "https://pytorch.org/docs/stable/torchvision/models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGn2mgFquX4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucjsm9MdyyUd",
        "colab_type": "text"
      },
      "source": [
        "# Download an image and imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsQZLe1_umus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Tiger_in_Ranthambhore.jpg/1024px-Tiger_in_Ranthambhore.jpg -O tiger.jpg\n",
        "!wget -q https://github.com/nmilosev/pytorch-arm-builds/raw/master/imagenet_classes.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTfDx6nDwJSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('imagenet_classes.txt') as f:\n",
        "    labels = [line.strip() for line in f.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OukN4S9ayXoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuxWGEFdy2xF",
        "colab_type": "text"
      },
      "source": [
        "# Initialize model\n",
        "\n",
        "Do not forget to enable evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw7eePWcvUam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = models.shufflenet_v2_x1_0(pretrained=True)\n",
        "net.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOo_nPUhy67P",
        "colab_type": "text"
      },
      "source": [
        "# Normalization\n",
        "\n",
        "Standard procedure of normalizing ImageNet images. This is so our image is in the same representation as the images in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGWX7JcWu9zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIwXId5jzUVf",
        "colab_type": "text"
      },
      "source": [
        "# Helper method\n",
        "\n",
        "Here we define a helper method for inference which receives a PIL image and returns top 5 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VERRua78zHEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(img):\n",
        "    img_t = transform(img)\n",
        "    batch_t = torch.unsqueeze(img_t, 0)\n",
        "    out = net(batch_t)\n",
        "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    _, indices = torch.sort(out, descending=True)\n",
        "    result = [(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aWlY5sRzZBs",
        "colab_type": "text"
      },
      "source": [
        "# Load image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atv5NeFGv4qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.open('tiger.jpg')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmPTl10Mzb5D",
        "colab_type": "text"
      },
      "source": [
        "# Run inference on our image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4o3wSX6v5Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infer(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}